{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCD Professional Academy Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "[The National Centers for Environment Information](https://www.ncei.noaa.gov) maintains one of the most significant archives on Earth, managing more than 30 petabytes of data and information that spans the entire spectrum of Earth’s environmental systems and cycles with comprehensive oceanic, atmospheric, and geophysical data.\n",
    "\n",
    "The [Storm Events Database](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00773) is an integrated database of severe weather events across the United States from 1950 to this year, with information about a storm event's location, azimuth, distance, impact, and severity, including the cost of damages to property and crops, loss of life, injuries, property damage, disruption to commerce, etc.\n",
    "\n",
    "This dataset allows identify the most severe storms and damage caused by them, as define correlations between the features that compose the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "The datasets are provided via [bulk download](https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/).\n",
    "There are 3 files linked by the event ID number. Details, locations and fatalities\n",
    "\n",
    "* Events Details file: The storm event description and data captured\n",
    "* Events Location file: The storm location data\n",
    "* Event fatalities file: the fatalities related to the storm\n",
    "\n",
    "The full descripiotn of all features as described [here](https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/Storm-Data-Bulk-csv-Format.pdf). The datasets relevants to this project are Storm details and fatalities file with the set of features described below:\n",
    "\n",
    "### Event Details file\n",
    "Named as `StormEvents_details-ftp_v1.0_dYYYY_cYYYYMMdd.csv` where dYYYY = data year and cYYYYMMdd = file creation date \n",
    "\n",
    "* `begin_yearmonth`: Ex: 201212 (YYYYMM format) The year and month that the event began \n",
    "* `begin_day`: Ex: 31 (DD format) The day of the month that the event began \n",
    "* `begin_time`: Ex: 2359 (hhmm format) The time of day that the event began \n",
    "* `end_yearmonth` Ex: Ex: 201301 (YYYYMM format) The year and month that the event ended\n",
    "* `end_day` Ex: 01 (DD format) The day of the month that the event ended\n",
    "* `end_time` Ex: 0001 (hhmm format) The time of day that the event ended\n",
    "* `episode_id` Ex: 61280, 62777, 63250 ID assigned by NWS to denote the storm episode;\n",
    "* `event_id` Ex: 383097, 374427, 364175 ID assigned by NWS for each individual storm event contained within a storm episode; links\n",
    "the record with the same event in the storm_event_details, storm_event_locations and\n",
    "storm_event_fatalities tables (Primary database key field).\n",
    "* `state` Ex: GEORGIA, WYOMING, COLORADO The state name where the event occurred (no State ID’s are included here; State Name is spelled out in ALL CAPS).\n",
    "* `year` Ex: 2000, 2006, 2012 The four digit year for the event in this record.\n",
    "* `month_name` Ex: January, February, March The name of the month for the event in this record (spelled out; not abbreviated).\n",
    "* `event_type` Ex: Hail, Thunderstorm Wind, Snow, Ice (spelled out; not abbreviated)\n",
    "* `begin_date_time` Ex: 04/1/2012 20:48:00\n",
    "MM/DD/YYYY hh:mm:ss (24 hour time usually in LST)\n",
    "* `end_date_time` Ex: 04/1/2012 21:03:00\n",
    "MM/DD/YYYY hh:mm:ss (24 hour time usually in LST)\n",
    "* `injuries_direct` Ex: 1, 0, 56\n",
    "The number of injuries directly caused by the weather event.\n",
    "* `injuries_indirect` Ex: 0, 15, 87\n",
    "The number of injuries indirectly caused by the weather event.\n",
    "* `deaths_direct` Ex: 0, 45, 23\n",
    "The number of deaths directly caused by the weather event.\n",
    "* `deaths_indirect` Ex: 0, 4, 6\n",
    "The number of deaths indirectly caused by the weather event.\n",
    "* `damage_property` Ex: 10.00K, 0.00K, 10.00M\n",
    "The estimated amount of damage to property incurred by the weather event (e.g. 10.00K =\n",
    "$10,000; 10.00M = $10,000,000)\n",
    "* `damage_crops` Ex: 0.00K, 500.00K, 15.00M\n",
    "The estimated amount of damage to crops incurred by the weather event (e.g. 10.00K =\n",
    "$10,000; 10.00M = $10,000,000).\n",
    "* `magnitude` Ex: 0.75, 60, 0.88, 2.75\n",
    "The measured extent of the magnitude type ~ only used for wind speeds (in knots) and hail size\n",
    "(in inches to the hundredth).\n",
    "* `magnitude_type`: Ex: EG, MS, MG, ES\n",
    "EG = Wind Estimated Gust; \n",
    "ES = Estimated Sustained Wind; \n",
    "MS = Measured Sustained Wind;\n",
    "MG = Measured Wind Gust (no magnitude is included for instances of hail).\n",
    "* `tor_f_scale` Ex: EF0, EF1, EF2, EF3, EF4, EF5\n",
    "Enhanced Fujita Scale describes the strength of the tornado based on the amount and type of\n",
    "damage caused by the tornado. The F-scale of damage will vary in the destruction area;\n",
    "therefore, the highest value of the F-scale is recorded for each event.\n",
    "|F-sccale|\n",
    "|-----------------------------------------|\n",
    "|EF0 – Light Damage (40 – 72 mph)|\n",
    "|EF1 – Moderate Damage (73 – 112 mph)|\n",
    "|EF2 – Significant damage (113 – 157 mph)|\n",
    "|EF3 – Severe Damage (158 – 206 mph)|\n",
    "|EF4 – Devastating Damage (207 – 260 mph)|\n",
    "|EF5 – Incredible Damage (261 – 318 mph)|\n",
    "\n",
    "* `tor_length` Ex: 0.66, 1.05, 0.48\n",
    "Length of the tornado or tornado segment while on the ground (in miles to the tenth).\n",
    "* `tor_width` Ex: 25, 50, 2640, 10\n",
    "\n",
    "### Storm Data Fatality File \n",
    "Named `StormEvents_fatalities-ftp_v1.0_dYYYY_cYYYYMMdd.csv.gz` where dYYYY = data year and cYYYYMMdd = file creation date\n",
    "\n",
    "* `fatality_id` Ex: 17582, 17590, 17597, 18222\n",
    "ID assigned by NWS to denote the individual fatality that occurred)\n",
    "* `event_id` Ex: 383097, 374427, 364175\n",
    "ID assigned by NWS for each individual storm event contained within a storm episode; links the\n",
    "record with the same event in the storm_event_details, storm_event_locations and\n",
    "storm_event_fatalities tables (Primary database key field)\n",
    "* `fatality_type` Ex: D , I\n",
    "(D = Direct Fatality; I = Indirect Fatality; assignment of this is determined by NWS software;\n",
    "details below are from NWS Directve 10-1605 at\n",
    "http://www.nws.noaa.gov/directives/sym/pd01016005curr.pdf, Section 2.6)\n",
    "* `fatality_date` Ex: 4/3/2012 00:00\n",
    "MM/DD/YYYY hh:mm (time is usually 00.00)\n",
    "* `fatality_age` Ex: 38, 25, 69, 54\n",
    "The age in years of the fatality (sometimes ‘null’ if unknown)\n",
    "* `fatality_sex` Ex: M, F\n",
    "The gender of the fatality (sometimes ‘null’ if unknown)\n",
    "* `fatality_location` Ex: UT, OU, MH, PS\n",
    "|Direct Fatality Location Table|\n",
    "|------------------------------|\n",
    "|BF Ball Field|\n",
    "|BO Boating|\n",
    "|BU Business|\n",
    "|CA Camping|\n",
    "|CH Church|\n",
    "|EQ Heavy Equip/Construction\\\n",
    "|GF Golfing|\n",
    "|IW In Water|\n",
    "|LS Long Span Roof|\n",
    "|MH Mobile/Trailer Home|\n",
    "|OT Other/Unknown|\n",
    "|OU Outside/Open Areas|\n",
    "|PH Permanent Home|\n",
    "|PS Permanent Structure|\n",
    "|SC School|\n",
    "|TE Telephone|\n",
    "|UT Under Tree|\n",
    "|VE Vehicle and/or Towed Trailer|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Downloading files\n",
    "\n",
    "> **This section takes a bit of time, please wait until it completes downloading all datases**.\n",
    "\n",
    "First all files needs to be downloaded from bulk download website. The website provides files from 1950 until current year. To automate the download will use BeatifulSoup to scrape the website and download all csv datasets. The desired files have the extension as `.csv.gz`. The files will be saved to datasets folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "bulk_url = 'https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/'\n",
    "html_text = requests.get(bulk_url).text\n",
    "soup = BeautifulSoup(html_text,'html.parser')\n",
    "files = []\n",
    "for link in soup.find_all(href=re.compile(\"\\\\.csv\\\\.gz\")):\n",
    "    file_link = link.get('href')\n",
    "    files.append(file_link)\n",
    "    download_url = \"{}/{}\".format(bulk_url,file_link)\n",
    "    r = requests.get(download_url,allow_redirects=True)\n",
    "    with open(\"datasets/{}\".format(file_link), 'wb') as f:\n",
    "        f.write(r.content)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading datasets into Pandas\n",
    "After downloading the datasets, will load all files into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2171, 51)\n",
      "(19, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>FAT_YEARMONTH</th>\n",
       "      <th>FAT_DAY</th>\n",
       "      <th>FAT_TIME</th>\n",
       "      <th>FATALITY_ID</th>\n",
       "      <th>FATALITY_TYPE</th>\n",
       "      <th>FATALITY_DATE</th>\n",
       "      <th>FATALITY_AGE</th>\n",
       "      <th>FATALITY_SEX</th>\n",
       "      <th>FATALITY_LOCATION</th>\n",
       "      <th>EVENT_YEARMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197204</td>\n",
       "      <td>3</td>\n",
       "      <td>1840</td>\n",
       "      <td>197204</td>\n",
       "      <td>3</td>\n",
       "      <td>1840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9983345</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197201</td>\n",
       "      <td>9</td>\n",
       "      <td>2320</td>\n",
       "      <td>197201</td>\n",
       "      <td>9</td>\n",
       "      <td>2320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10049806</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197207</td>\n",
       "      <td>1</td>\n",
       "      <td>1700</td>\n",
       "      <td>197207</td>\n",
       "      <td>1</td>\n",
       "      <td>1700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10064819</td>\n",
       "      <td>NEBRASKA</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197203</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>197203</td>\n",
       "      <td>2</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9978347</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197205</td>\n",
       "      <td>31</td>\n",
       "      <td>1145</td>\n",
       "      <td>197205</td>\n",
       "      <td>31</td>\n",
       "      <td>1145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10079162</td>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           197204          3        1840         197204        3      1840   \n",
       "1           197201          9        2320         197201        9      2320   \n",
       "2           197207          1        1700         197207        1      1700   \n",
       "3           197203          2         700         197203        2       700   \n",
       "4           197205         31        1145         197205       31      1145   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID          STATE  STATE_FIPS  ...  FAT_YEARMONTH  \\\n",
       "0         NaN   9983345       ARKANSAS           5  ...            NaN   \n",
       "1         NaN  10049806    MISSISSIPPI          28  ...            NaN   \n",
       "2         NaN  10064819       NEBRASKA          31  ...            NaN   \n",
       "3         NaN   9978347        ALABAMA           1  ...            NaN   \n",
       "4         NaN  10079162  NEW HAMPSHIRE          33  ...            NaN   \n",
       "\n",
       "  FAT_DAY FAT_TIME FATALITY_ID  FATALITY_TYPE FATALITY_DATE  FATALITY_AGE  \\\n",
       "0     NaN      NaN         NaN            NaN           NaN           NaN   \n",
       "1     NaN      NaN         NaN            NaN           NaN           NaN   \n",
       "2     NaN      NaN         NaN            NaN           NaN           NaN   \n",
       "3     NaN      NaN         NaN            NaN           NaN           NaN   \n",
       "4     NaN      NaN         NaN            NaN           NaN           NaN   \n",
       "\n",
       "  FATALITY_SEX FATALITY_LOCATION EVENT_YEARMONTH  \n",
       "0          NaN               NaN             NaN  \n",
       "1          NaN               NaN             NaN  \n",
       "2          NaN               NaN             NaN  \n",
       "3          NaN               NaN             NaN  \n",
       "4          NaN               NaN             NaN  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def load_df(file_path):\n",
    "    with gzip.open(file_path) as f:\n",
    "        df = pd.read_csv(f)\n",
    "    return df\n",
    "\n",
    "storm_details_df = load_df('datasets/StormEvents_details-ftp_v1.0_d1972_c20220425.csv.gz')\n",
    "storm_fatalities_df = load_df('datasets/StormEvents_fatalities-ftp_v1.0_d1972_c20220425.csv.gz')\n",
    "storm_locations_df = load_df('datasets/StormEvents_locations-ftp_v1.0_d1972_c20220425.csv.gz')\n",
    "\n",
    "storm_df = pd.merge(storm_details_df,storm_fatalities_df,how=\"left\",on=[\"EVENT_ID\"])\n",
    "print(storm_details_df.shape)\n",
    "print(storm_fatalities_df.shape)\n",
    "storm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* DOC/NOAA/NESDIS/NCEI > National Centers for Environmental Information, NESDIS, NOAA, U.S. Department of Commerce\n",
    "* The Severe Weather Data Inventory (SWDI): a Geospatial Database of Severe Weather Data at the NOAA National Centers for Environmental Information (NCEI)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
